LSTM＋CTC被广泛的用在语音识别领域把音频解码成汉字，从这个角度说，OCR其实就是把图片解码成汉字，并没有太本质的区别。而且在整个过程中，不需要提前知道究竟要解码成几个字。

crnn原理:

https://blog.csdn.net/rogerchen1983/article/details/91910514

通过CTC模型训练后，对结果中去掉间隔字符、去掉重复字符（如果同个字符连续出现，则表示只有1个字符，如果中间有间隔字符，则表示该字符出现多次），如下图所示：
先来梳理一下要实现“文本识别”的模型，需要具备哪些要素：

（1）首先是要读取输入的图像，提取图像特征，因此，需要有个卷积层用于读取图像和提取特征。具体原理可详见本公众号的文章：白话卷积神经网络（CNN）；

（2）由于文本序列是不定长的，因此在模型中需要引入RNN（循环神经网络），一般是使用双向LSTM来处理不定长序列预测的问题。具体原理可详见本公众号的文章：白话循环神经网络（RNN）；

（3）为了提升模型的适用性，最好不要要求对输入字符进行分割，直接可进行端到端的训练，这样可减少大量的分割标注工作，这时就要引入CTC模型（Connectionist temporal classification， 联接时间分类），来解决样本的分割对齐的问题。

（4）最后根据一定的规则，对模型输出结果进行纠正处理，输出正确结果。

以上就是“文本识别”模型的几个必须具备的要素。

CRNN模型主要由以下三部分组成：
（1）卷积层：从输入图像中提取出特征序列；
（2）循环层：预测从卷积层获取的特征序列的标签分布；
（3）转录层：把从循环层获取的标签分布通过去重、整合等操作转换成最终的识别结果。
下面将展开对这三个层进行介绍：
（1）卷积层
① 预处理
CRNN对输入图像先做了缩放处理，把所有输入图像缩放到相同高度，默认是32，宽度可任意长。
② 卷积运算
由标准的CNN模型中的卷积层和最大池化层组成，结构类似于VGG，如下图：
   Type
       Configurations



③ 提取序列特征

提取的特征序列中的向量是在特征图上从左到右按照顺序生成的，用于作为循环层的输入，每个特征向量表示了图像上一定宽度上的特征，默认的宽度是1，也就是单个像素。由于CRNN已将输入图像缩放到同样高度了，因此只需按照一定的宽度提取特征即可。如下图所示：



（2）循环层

循环层由一个双向LSTM循环神经网络构成，预测特征序列中的每一个特征向量的标签分布。

由于LSTM需要有个时间维度，在本模型中把序列的 width 当作LSTM 的时间 time steps。

其中，“Map-to-Sequence”自定义网络层主要是做循环层误差反馈，与特征序列的转换，作为卷积层和循环层之间连接的桥梁，从而将误差从循环层反馈到卷积层。

 

（3）转录层

转录层是将LSTM网络预测的特征序列的结果进行整合，转换为最终输出的结果。

在CRNN模型中双向LSTM网络层的最后连接上一个CTC模型，从而做到了端对端的识别。所谓CTC模型（Connectionist Temporal Classification，联接时间分类），主要用于解决输入数据与给定标签的对齐问题，可用于执行端到端的训练，输出不定长的序列结果。

由于输入的自然场景的文字图像，由于字符间隔、图像变形等问题，导致同个文字有不同的表现形式，但实际上都是同一个词，如下图：



而引入CTC就是主要解决这个问题，通过CTC模型训练后，对结果中去掉间隔字符、去掉重复字符（如果同个字符连续出现，则表示只有1个字符，如果中间有间隔字符，则表示该字符出现多次），如下图所示：


 ———————————————— 
版权声明：本文为CSDN博主「雪饼ai」的原创文章，遵循CC 4.0 by-sa版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/rogerchen1983/article/details/91910514

网络分析： 
1：input： 输入文字块，归一化到32*w 即height缩放到32，宽度按高度的比率缩 放，当然，也可以缩放到自己想要的宽度，如128（测试时统一缩放到[32，128],训练时为批次训练，缩放到[32,Wmax]） 
下面以32*128（w,h）分析 
2：conv3层时数据大小为256*8*32，两个pooling层宽高各除以4 
3：pooling2层时 步长为（2，1） dilation （1，1） 
所以此时输出为256*4*33 
4：bn层不改变输出的大小（就是做个归一化，加速训练收敛，个人理解），同样p3层时,w+1,所以pooling3层时，输出为512*2*34 
5：conv7层时，kernel 为2*2，stride(1,1) padding(0,0) 
Wnew = (2 + 2 * padW - kernel ) / strideW + 1 = 1 
Hnew = 33 
所以conv7层输出为512*1*33 
6: 后面跟两个双向Lstm,隐藏节点都是256 
Blstm1输出33*1*256 
Blstm2输出33*1*5530 5530 = 字符个数 + 非字符 = 5529 + 1 
最终的输出结果直观上可以想象成将128分为33份，每一份对应5530个类别的概率




